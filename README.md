
# Reading List for Topics in Artificial Social Intelligence  [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/topics/awesome)
By [Dong Won Lee](https://dongwonl.com/) from the [Personal Robots Group](https://www.media.mit.edu/groups/personal-robots/overview/) at [MIT](https://www.mit.edu/) and [Leena Mathur](https://l-mathur.github.io) from the [MultiComp Lab](http://multicomp.cs.cmu.edu) at CMU's [School of Computer Science](https://www.cs.cmu.edu). 

If there are any topics, papers, or datasets we missed, please let us know! Feel free to contribute to this list by sending a pull request or emailing dongwonl@mit.edu or lmathur@andrew.cmu.edu 

## Social Intelligence Definitions

[The measurement of social intelligence](https://psycnet.apa.org/buy/1928-03750-001), Journal of Applied Psychology, 1928

## Psychology and Neural Perspectives on Social Intelligence

[The media equation: How people treat computers, television, and new media like real people and places](https://psycnet.apa.org/record/1996-98923-000), Stanford, 1996

## Artificial Social Intelligence

[Towards Social Artificial Intelligence:
Nonverbal Social Signal Prediction in A Triadic Interaction](https://openaccess.thecvf.com/content_CVPR_2019/papers/Joo_Towards_Social_Artificial_Intelligence_Nonverbal_Social_Signal_Prediction_in_a_CVPR_2019_paper.pdf) CVPR, 2019 

[Learning Social Affordance for Human-Robot Interaction](https://arxiv.org/pdf/1604.03692v2.pdf), IJCAI, 2016

[Didnâ€™t see that coming: a survey on non-verbal social human behavior forecasting](https://arxiv.org/pdf/1604.03692v2.pdf), PMLR, 2022

[Learning to Listen: Modeling Non-Deterministic Dyadic Facial Motion](https://openaccess.thecvf.com/content/CVPR2022/papers/Ng_Learning_To_Listen_Modeling_Non-Deterministic_Dyadic_Facial_Motion_CVPR_2022_paper.pdf), CVPR 2022

[Socially and contextually aware human motion and pose forecasting](https://ras.papercept.net/images/temp/IROS/files/2815.pdf) IROS 2020


## Applications 

## Datasets

| Dataset | Domain | Paper | Data|
|:-----------|:----------------------------|:------------:|:------------:|
| `PATS` | multimodal co-speech gestures | [ECCV 2020 paper](https://arxiv.org/abs/2007.12553) | [data](https://chahuja.com/pats/) + [code](https://github.com/chahuja/pats)
|`Social-IQ`| multimodal video qa | [CVPR 2019 paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Zadeh_Social-IQ_A_Question_Answering_Benchmark_for_Artificial_Social_Intelligence_CVPR_2019_paper.pdf) | [data + code](https://github.com/A2Zadeh/Social-IQ)
|`Social-IQa`| language qa | [EMNLP 2019 paper](https://arxiv.org/pdf/1904.09728.pdf) | [data + code](https://github.com/google/BIG-bench/blob/main/bigbench/benchmark_tasks/social_iqa/README.md)
|`CMU-MOSEI`| multimodal sentiment and emotion intensity | [ACL 2018 paper](https://aclanthology.org/P18-1208.pdf) | [data + code](https://github.com/A2Zadeh/CMU-MultimodalSDK)
| `IEMOCAP` | multimodal emotional dyadic motion capture | [LREC 2008 paper](https://link.springer.com/content/pdf/10.1007/s10579-008-9076-6.pdf) | [data](https://sail.usc.edu/software/databases/) 
| `RoomReader` | multimodal multiparty engagement in online conference | [LREC 2022 paper](http://www.lrec-conf.org/proceedings/lrec2022/pdf/2022.lrec-1.268.pdf) | [data](https://sigmedia.tcd.ie/) 
| `MUMBAI` | multi-person, multimodal board game affect and interaction analysis dataset | [Journal on Multimodal User Interfaces 2021 paper](https://link.springer.com/article/10.1007/s12193-021-00364-0) | [data](https://github.com/dmetehan/MUMBAI) 
| `iMiGUE` | An Identity-free Video Dataset for Micro-Gesture Understanding and
Emotion Analysis | [CVPR 2022 paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_iMiGUE_An_Identity-Free_Video_Dataset_for_Micro-Gesture_Understanding_and_Emotion_CVPR_2021_paper.pdf) | [data]((https://github.com/linuxsino/iMiGUE)) 





## Resources

### Relevant Courses 
[Multimodal Probabilistic Learning of Human Communication](https://people.ict.usc.edu/~soleymani/files/HumanCommunicationLearning-Spring2021.pdf), Mohammad Soleymani @ USC, Spring 2021

### Workshops

[Artificial Social Intelligence](https://sites.google.com/berkeley.edu/artificial-social-intelligence), CVPR 2022

[Social Intelligence in Humans and Robots (2.0)](https://social-intelligence-human-ai.github.io), RSS 2022

[Social Intelligence in Humans and Robots (1.0)](https://social-intelligence-human-ai.github.io/), ICRA 2021

[Social Affective Multimodal Interaction for Health (SAMIH 2.0)](https://sites.google.com/view/samih2021/home), ICMI 2021

[Socially-Informed AI for Healthcare](https://social-ai-for-healthcare.github.io), ICMI 2021

[Social Affective Multimodal Interaction for Health (SAMIH 1.0)](https://sites.google.com/view/wsamih/), ICMI 2020

### Dissertations

[Communication Beyond Words: Grounding Visual Body Motion with Language](https://lti.cs.cmu.edu/sites/default/files/ahuja%2C%20chaitanya%20-%20Thesis.pdf), 2022, [Chaitanya Ahuja](https://chahuja.com)

[Social and Affective Machine Learning](https://www.media.mit.edu/publications/social-and-affective-machine-learning/), 2019, [Natasha Jaques](https://natashajaques.ai) 

[A Bayesian Theory of Mind Approach to Nonverbal Communication for Human-Robot Interactions](https://www.media.mit.edu/publications/jinjoolee-phd-2017/), 2017, Jin Joo Lee

[Towards Human-Centered Optimality Criteria](https://dspace.mit.edu/bitstream/handle/1721.1/140992/ghandeharioun-asma_gh-phd-MAS-2021-thesis.pdf?sequence=1&isAllowed=y), 2021, Asma Ghandeharioun



